{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c988b02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_squared_log_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fb3d4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour_x</th>\n",
       "      <th>Hour_y</th>\n",
       "      <th>DOTW_x</th>\n",
       "      <th>DOTW_y</th>\n",
       "      <th>Holi</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humi</th>\n",
       "      <th>WS</th>\n",
       "      <th>THI</th>\n",
       "      <th>WCT</th>\n",
       "      <th>Cons_1</th>\n",
       "      <th>Holi_1</th>\n",
       "      <th>Cons_7</th>\n",
       "      <th>Holi_7</th>\n",
       "      <th>Cons_avg</th>\n",
       "      <th>Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-11 18:00</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.840000e-16</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.29672</td>\n",
       "      <td>5.103854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-11 19:00</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.55240</td>\n",
       "      <td>4.872989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-11 20:00</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.80320</td>\n",
       "      <td>4.872989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-11 21:00</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.88680</td>\n",
       "      <td>4.872989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-11 22:00</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.13072</td>\n",
       "      <td>4.413133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date    Hour_x        Hour_y    DOTW_x   DOTW_y  Holi  Temp  \\\n",
       "0  2016-01-11 18:00 -1.000000 -1.840000e-16  0.781831  0.62349     0   5.9   \n",
       "1  2016-01-11 19:00 -0.965926  2.588190e-01  0.781831  0.62349     0   6.0   \n",
       "2  2016-01-11 20:00 -0.866025  5.000000e-01  0.781831  0.62349     0   6.0   \n",
       "3  2016-01-11 21:00 -0.707107  7.071068e-01  0.781831  0.62349     0   6.0   \n",
       "4  2016-01-11 22:00 -0.500000  8.660254e-01  0.781831  0.62349     0   5.6   \n",
       "\n",
       "   Humi   WS       THI       WCT  Cons_1  Holi_1  Cons_7  Holi_7  Cons_avg  \\\n",
       "0  92.0  5.0  43.29672  5.103854       0       0       0       0       0.0   \n",
       "1  91.0  6.0  43.55240  4.872989       0       0       0       0       0.0   \n",
       "2  88.0  6.0  43.80320  4.872989       0       0       0       0       0.0   \n",
       "3  87.0  6.0  43.88680  4.872989       0       0       0       0       0.0   \n",
       "4  88.0  6.0  43.13072  4.413133       0       0       0       0       0.0   \n",
       "\n",
       "   Consumption  \n",
       "0          330  \n",
       "1         1430  \n",
       "2          690  \n",
       "3          780  \n",
       "4          620  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'C:/Users/user/Desktop/PLoSONE/data/'\n",
    "\n",
    "data = pd.read_csv(path + 'dataset_household_PLoS ONE.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a30eeb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour_x</th>\n",
       "      <th>Hour_y</th>\n",
       "      <th>DOTW_x</th>\n",
       "      <th>DOTW_y</th>\n",
       "      <th>Holi</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humi</th>\n",
       "      <th>WS</th>\n",
       "      <th>THI</th>\n",
       "      <th>WCT</th>\n",
       "      <th>Cons_1</th>\n",
       "      <th>Holi_1</th>\n",
       "      <th>Cons_7</th>\n",
       "      <th>Holi_7</th>\n",
       "      <th>Cons_avg</th>\n",
       "      <th>Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.840000e-16</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>92.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.29672</td>\n",
       "      <td>5.103854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.965926</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.55240</td>\n",
       "      <td>4.872989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.80320</td>\n",
       "      <td>4.872989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.88680</td>\n",
       "      <td>4.872989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.781831</td>\n",
       "      <td>0.62349</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43.13072</td>\n",
       "      <td>4.413133</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hour_x        Hour_y    DOTW_x   DOTW_y  Holi  Temp  Humi   WS       THI  \\\n",
       "0 -1.000000 -1.840000e-16  0.781831  0.62349     0   5.9  92.0  5.0  43.29672   \n",
       "1 -0.965926  2.588190e-01  0.781831  0.62349     0   6.0  91.0  6.0  43.55240   \n",
       "2 -0.866025  5.000000e-01  0.781831  0.62349     0   6.0  88.0  6.0  43.80320   \n",
       "3 -0.707107  7.071068e-01  0.781831  0.62349     0   6.0  87.0  6.0  43.88680   \n",
       "4 -0.500000  8.660254e-01  0.781831  0.62349     0   5.6  88.0  6.0  43.13072   \n",
       "\n",
       "        WCT  Cons_1  Holi_1  Cons_7  Holi_7  Cons_avg  Consumption  \n",
       "0  5.103854       0       0       0       0       0.0          330  \n",
       "1  4.872989       0       0       0       0       0.0         1430  \n",
       "2  4.872989       0       0       0       0       0.0          690  \n",
       "3  4.872989       0       0       0       0       0.0          780  \n",
       "4  4.413133       0       0       0       0       0.0          620  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_drop = data.drop(columns = 'Date', axis = 1)\n",
    "data_drop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde1fe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data_drop.iloc[:2310]\n",
    "x_test = data_drop.iloc[2310:]\n",
    "y_train = data_drop.iloc[:2310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f9fac8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 정의 \n",
    "y = y_train['Consumption']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "988dd629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋 분리\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(x_train, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba5b526f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# GridSEarch\u001b[39;00m\n\u001b[0;32m     14\u001b[0m gr \u001b[38;5;241m=\u001b[39m GridSearchCV(model, param_grid \u001b[38;5;241m=\u001b[39m params, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(gr\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\joblib\\parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\joblib\\parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\joblib\\parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\joblib\\parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\xgboost\\sklearn.py:1025\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1014\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m (\n\u001b[0;32m   1017\u001b[0m     model,\n\u001b[0;32m   1018\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1024\u001b[0m )\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\xgboost\\core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    619\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 620\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\xgboost\\training.py:185\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py_38\\lib\\site-packages\\xgboost\\core.py:1918\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_dmatrix_features(dtrain)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1918\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1919\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1922\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# xgb\n",
    "model = XGBRegressor()\n",
    "\n",
    "params = {\n",
    "    'n_estimators': [250, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [6, 8, 10],\n",
    "    'subsample': [0.5, 0.75, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.75, 1.0],\n",
    "    'booster': ['gbtree', 'dart']\n",
    "         }\n",
    "\n",
    "# GridSEarch\n",
    "gr = GridSearchCV(model, param_grid = params, cv = 5)\n",
    "gr.fit(X_train, Y_train)\n",
    "\n",
    "print(gr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb746eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 330.00181948,  369.96595259,  539.99149404,  222.32179841,\n",
       "        559.94314052,  279.99659255, 1110.78058546,  329.98815302,\n",
       "        379.95621884,  319.97761921,  449.60873146,  806.00870606,\n",
       "        489.98691941,  409.88530185,  429.61814518,  680.09145585,\n",
       "        819.70103713,  780.20641541,  909.63302842,  690.46588288,\n",
       "       1008.33868886,  279.99270318,  290.73666517,  359.17081457,\n",
       "       2068.40385248,  609.90324819,  519.91897932,  351.1232756 ,\n",
       "        270.05509805,  808.08786388,  300.01872162,  279.99600392,\n",
       "        279.97662587,  310.01748943,  359.94986589,  389.96401786,\n",
       "        329.94038058,  279.88549334,  219.75116066,  439.88048155,\n",
       "       2081.20408583,  319.53127135,  529.97139517,  279.98763108,\n",
       "        345.79448401,  280.06245821,  435.74386868,  270.08518456,\n",
       "        389.97749441,  208.73153007,  280.03391543,  956.54209648,\n",
       "        350.10980234,  279.94290292,  330.02536015,  379.9529555 ,\n",
       "        609.93467563,  329.99294254,  699.6023453 ,  250.18263819,\n",
       "        320.08607805,  340.16516387, 1548.32590323,  870.40884122,\n",
       "        519.98770669, 1197.44341839,  209.71435161,  509.94613361,\n",
       "        269.77818511,  320.20938674,  509.71734547,  187.40931727,\n",
       "        620.06847404,  939.26092578,  249.98532619,  319.99336872,\n",
       "        429.97453172, 2291.28329532,  349.98515337,  250.06460859,\n",
       "        329.99784405,  661.68133358,  270.04470996,  280.07407913,\n",
       "        760.31798211,  300.02141319, 2048.1135241 , 1465.82182577,\n",
       "        349.97721684,  379.99154683,  239.40877434,  211.65892166,\n",
       "        389.76286827,  360.01545147,  210.68932798, 1119.65705824,\n",
       "        878.91661739,  359.94925993,  319.98071343,  520.13113471,\n",
       "        289.98954907,  228.9770966 ,  249.80512727,  280.02858471,\n",
       "       1580.71027197,  197.1973705 ,  300.02037897,  359.98754825,\n",
       "        349.96495107, 2354.21194093,  269.89874858,  229.97098672,\n",
       "        229.47682142,  249.79334768,  345.63357709,  340.24512623,\n",
       "        580.20067824,  230.14567716,  194.37500012,  270.06100959,\n",
       "        640.14573638, 1077.60102032, 1098.56038011,  559.18700376,\n",
       "        289.94947515,  220.71274317,  259.99785307,  229.15223655,\n",
       "        449.98328116,  359.94342631,  319.99174586,  340.01765021,\n",
       "        289.15003705,  349.89108641,  360.03399407, 2144.95099262,\n",
       "       1107.27504069,  609.94760395,  319.98918715,  270.03220351,\n",
       "        459.96445538,  240.0603423 ,  990.01458533,  879.0367291 ,\n",
       "       1721.6304225 ,  740.43158542, 1305.33001807,  319.9960603 ,\n",
       "       1166.36425267,  709.9112988 , 1482.72528222,  590.18132606,\n",
       "        228.30427075,  340.04307697,  879.75593638,  228.59691782,\n",
       "        280.00870378,  219.91622778,  260.42372201,  399.987046  ,\n",
       "        190.03967322,  349.94613331, 2723.76996787,  879.60096914,\n",
       "        319.9960603 ,  978.53582468,  390.08701762,  189.10957052,\n",
       "        230.23032987,  579.99338592,  310.00464695,  549.98688795,\n",
       "        740.15286269,  382.47225899,  300.00174332, 1594.14043284,\n",
       "        249.76242883,  399.94972496,  209.43566341,  269.85340845,\n",
       "        319.99493345,  369.97435046, 1436.53823001,  229.59178489,\n",
       "        269.9182216 , 1754.38674716, 1410.27199047,  269.8722544 ,\n",
       "       1414.36929479,  269.98368793, 1553.72731141,  539.92861361,\n",
       "        599.99031445,  405.42336029,  329.99031533,  359.94918396,\n",
       "        912.71287811,  760.76649036, 1543.65793991,  239.39753234,\n",
       "        429.9458984 , 1229.04681589,  207.93957315,  955.1033068 ,\n",
       "        289.98183561,  309.58113712, 1008.42813813,  719.73539011,\n",
       "        259.49160584, 1067.95744082,  559.9711009 ,  270.02910823,\n",
       "        379.93191843, 1363.48882723,  300.03556576,  310.01169986,\n",
       "        270.02175861,  430.03465425,  699.70959603,  819.16809034,\n",
       "        900.48795512,  840.17315426,  360.07824214, 1283.92476055,\n",
       "        289.9485524 ,  300.25370312,  519.86125424,  699.63551222,\n",
       "        300.03785074,  330.01997199,  378.98103418,  332.52924321,\n",
       "       1670.29775628, 1588.76474746,  399.99787863,  310.00259187,\n",
       "        240.10473561,  749.24184857, 1080.1911893 ,  410.07816782,\n",
       "        770.52144608,  249.75155385,  379.99198553,  230.66265568,\n",
       "        319.97958658,  590.06641393,  300.06741453, 2736.48339094,\n",
       "       1315.11878137,  290.05529139,  359.85099626,  559.94781251,\n",
       "        808.48435824,  280.04615013,  190.24706223,  310.08115871,\n",
       "        310.03549483,  730.47813037, 1066.80243547,  349.97719854,\n",
       "        310.03850945,  230.53459447,  339.98186662, 1457.62815539,\n",
       "        565.1269554 , 1734.03356581,  229.89263246,  339.98115095,\n",
       "        620.15642985,  340.07227845,  470.09125899,  329.63021431,\n",
       "        660.00716801, 1838.85308052,  192.54909411,  439.7093701 ,\n",
       "       2357.34368979,  319.88334966,  369.92534941,  190.96710107,\n",
       "        569.93082227,  520.14113846,  459.95322262,  670.31976308,\n",
       "        250.13116463,  240.04477724,  540.01834306,  214.88161174,\n",
       "       1515.65486629,  319.96331529,  260.16182853,  579.5176286 ,\n",
       "        300.13141608,  309.93857349,  730.24696715,  569.22668285,\n",
       "        770.64381854,  269.86822204, 1487.85616718,  230.02471962,\n",
       "        669.96331244,  310.00265625,  309.99921512,  361.75316975,\n",
       "        519.91556054,  600.11373995,  249.95661937,  460.01476157,\n",
       "        224.16012511, 1397.95408275,  469.72426881,  269.92940486,\n",
       "        194.3415431 ,  369.86633545,  750.69940551,  229.48436638,\n",
       "        589.95583479,  250.06620708,  750.33908248,  419.93509381,\n",
       "        289.99588537,  419.92806765,  629.93483458,  699.58371566,\n",
       "       1195.28196927,  281.1259493 , 2025.70876267,  957.05006871,\n",
       "        212.42916131,  849.57645894,  808.04494441,  500.00157971,\n",
       "       1065.36443201,  289.86204127,  349.97545336,  190.2273027 ,\n",
       "        269.96497704,  280.02574056,  290.00849674,  524.73278703,\n",
       "        280.01386383, 1260.7460698 , 1006.84573155, 2781.34502966,\n",
       "       2288.18343005,  630.15681934,  300.34169241,  499.8734155 ,\n",
       "        400.01208306,  231.03354022,  264.19327217,  229.80217584,\n",
       "       1763.74273253,  940.85307   ,  359.92007109,  300.01659073,\n",
       "        435.74386868,  280.35557656,  349.99358123,  193.24274008,\n",
       "        309.99963232,  310.2008993 ,  269.75706146, 1554.80561993,\n",
       "        379.97199889,  250.15105472, 1765.34956546,  389.93156091,\n",
       "        250.03526094,  410.1897921 ,  720.17391085,  770.15695354,\n",
       "        499.89015017,  300.03315707,  619.70160344,  222.53790523,\n",
       "        269.95839643,  269.91857801,  350.10239188,  186.79797497,\n",
       "        300.06471514, 1136.42223387,  559.95286296,  710.06524971,\n",
       "        339.79332676,  330.02898788,  319.99615293,  679.87727983,\n",
       "        260.28643306,  440.13239765,  330.02294784,  449.93356656,\n",
       "        380.04395816,  499.98566448, 1390.06644562,  289.9792521 ,\n",
       "        489.94198398,  589.94175756,  310.08788423,  280.01627575,\n",
       "        350.04861794,  195.78401702,  260.02979537,  261.74990902,\n",
       "       1367.06487874,  495.35064118,  808.75996128,  189.59645442,\n",
       "        390.12839392, 1836.73933697,  730.50672733,  289.99538722,\n",
       "        269.99280298,  310.0029896 ,  280.0727654 ,  249.66995994,\n",
       "       1067.82789159, 2249.82846029,  268.25428228,  790.89282257,\n",
       "        808.10822162, 2734.67508488,  250.1000973 ,  589.93471264,\n",
       "        808.31846445, 1415.077424  , 2716.20498162,  439.9326913 ,\n",
       "        249.96556045, 1366.88372709,  445.22149424, 1045.68111213,\n",
       "        980.44643331,  839.26411483,  309.94257549,  709.8308096 ,\n",
       "       1005.93840621, 1800.99159599,  359.93874295,  366.13752541,\n",
       "       1918.68089872,  299.89946315, 1006.679137  , 1603.73543048,\n",
       "        270.37265371, 1192.39815835,  259.98833737,  301.51617532,\n",
       "        450.00278076, 1668.36943983,  369.97454546,  300.02150582,\n",
       "       1369.27777511,  807.32329272, 2239.99447769, 1374.4845396 ,\n",
       "        649.78478796,  420.15899079,  479.64291772,  429.63384942,\n",
       "       1370.72466418,  359.8350393 ,  879.21268518,  660.09993821,\n",
       "        589.90726351,  229.04314666,  470.11541142,  240.38361413,\n",
       "        539.96064936,  310.23898309,  729.93344408,  340.30730941,\n",
       "        789.45212925,  280.35864624,  220.63727068, 1258.89072467,\n",
       "        640.10099163,  339.94639717,  500.00054458, 1257.94101302,\n",
       "       1206.61893621,  719.75976436,  489.98473863,  539.83115814,\n",
       "        360.01794906,  348.73568767,  849.70985203,  270.02442896,\n",
       "        290.07300913,  220.17297429,  290.02351877, 1336.82123614,\n",
       "        759.93789985, 1563.50207256,  319.9735604 ,  310.00455432,\n",
       "        330.00194015,  230.30606704,  250.80377891, 1572.38184952,\n",
       "        260.03105863,  450.01664847,  269.97659684,  229.91890627,\n",
       "        229.44179486,  291.52169105,  300.24213852,  429.96899409,\n",
       "        187.93444531, 1634.97913015,  359.94033593,  289.97858483,\n",
       "        400.03582607,  189.90164797,  270.12824699,  222.09140921,\n",
       "        530.08393698,  300.1038456 ,  489.07284822,  300.02150582,\n",
       "        231.31047157,  278.87035793,  699.78466375, 2096.11868435,\n",
       "        840.21726572,  669.90646063,  499.99829343,  300.02141319,\n",
       "        249.76208507,  269.99688865, 2750.06341158, 2757.22027362,\n",
       "        359.92939997,  830.18766395,  270.0489373 ,  289.9733406 ,\n",
       "        479.98183286,  359.93367163,  330.05070236,  268.96732006,\n",
       "        359.94627166,  550.02762338,  530.01734383,  449.97937649,\n",
       "        310.14700007,  269.98119066, 1749.27594416,  830.35471487,\n",
       "        988.1126663 ,  279.95633897,  710.37996971, 1464.89477886,\n",
       "        988.67659826, 1069.13709459,  320.24989521, 1277.13869128,\n",
       "        359.91603194,  689.99265649,  259.96285856,  499.81256164,\n",
       "       2758.26756079,  988.39424077,  417.14813791,  329.98912411,\n",
       "        549.97517958,  309.85273108,  300.02028634,  300.01872162,\n",
       "        220.47962235,  679.97432979,  290.01837735,  709.19625445,\n",
       "       1065.83859086,  289.95882346,  230.20126822,  188.29200466,\n",
       "        369.95144906,  460.19418152,  330.23180924,  274.09036778,\n",
       "        280.0799745 ,  690.14553246,  730.27419269, 2121.22572754,\n",
       "        240.16868255,  229.73594739, 1835.92669106,  299.97125272,\n",
       "        972.10986151,  330.00241937,  389.99564427,  780.47609273,\n",
       "        259.59971677,  290.03550799,  339.81523189,  450.86601893,\n",
       "        340.19692017,  319.97918192, 1723.08422916,  360.30698681,\n",
       "       1735.79698245,  289.91060092,  909.86348774,  349.96671228,\n",
       "        219.61960472,  309.99807451,  639.45396239,  250.02610947,\n",
       "        310.00891541,  196.85777847,  310.03610115,  239.89085072,\n",
       "        191.52280444, 1232.17738131,  709.97523293, 1709.89433767,\n",
       "        259.72051065,  461.67876288,  760.39971568,  259.79444177,\n",
       "        539.96138593,  279.98914804,  350.20745872, 1915.72629392,\n",
       "        228.63316582,  280.02923248,  721.88177848, 1047.36014907,\n",
       "        319.97483501,  269.55002047,  219.33951944,  350.08496392,\n",
       "       1363.7495416 , 2265.78543796,  469.52356713,  329.99190832,\n",
       "        694.35610479,  329.98593652,  309.99033431,  359.9215989 ,\n",
       "        319.99174586,  329.98593652,  329.83590007, 1367.439027  ,\n",
       "        920.24309175,  290.00253386,  191.95525998,  269.85275806,\n",
       "        859.96402831,  309.96074191, 1906.63685063,  209.97415153,\n",
       "        379.95731685,  679.87923926,  290.01221628,  339.96541512,\n",
       "        380.03838368,  585.17288949,  539.96960954,  350.04136963,\n",
       "        281.76581663,  459.11205006,  250.13672891,  629.12192559,\n",
       "        290.00760142,  289.9762189 ,  380.05130776,  270.09385991,\n",
       "        339.90325398,  850.11989547,  429.95718352,  759.03818787,\n",
       "        290.00531206,  619.94336374, 1164.31828073,  530.03258341,\n",
       "        808.34259125,  330.07320224,  469.94780919,  310.0237764 ,\n",
       "        619.91754989,  249.99001734,  310.0029896 ,  340.55112272,\n",
       "        270.1919564 ,  679.93471251,  339.98204584,  329.98912411,\n",
       "        280.02235005,  559.96053617,  300.05113422,  740.44637666,\n",
       "        290.01357876])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(random_state=42) # 다시 넣기\n",
    "xgb.fit(X_train, Y_train)\n",
    "\n",
    "y_pred = xgb.predict(X_valid)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b08914cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(979,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실제값 \n",
    "y_predict = xgb.predict(x_test).astype(int)\n",
    "y_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b5bc2ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 339,  300,  329,  300,  339,  289,  300,  329,  350,  890,  679,\n",
       "       2742,  790,  639,  420,  450,  599,  978, 1470,  699,  729,  550,\n",
       "        420,  319,  339,  339,  409,  319,  250,  319,  310,  330,  289,\n",
       "        330,  300,  289,  490,  310,  299,  250,  349,  440, 1763,  650,\n",
       "        710,  730,  289,  269,  310,  320,  230,  310,  319,  310,  679,\n",
       "        459,  780,  310,  300,  240,  310,  309,  249,  319,  289,  340,\n",
       "       1610,  698,  680,  499,  329,  310,  229,  329,  310,  240,  310,\n",
       "        319,  280,  420,  330,  350,  350,  389,  249,  309,  350, 1045,\n",
       "        465,  425, 1367, 1433,  710,  629,  409,  319,  229,  319,  329,\n",
       "        300,  240,  320,  420,  330,  280,  320,  310,  300,  329,  315,\n",
       "        385,  365,  435,  494, 1257, 1113,  714, 1027,  427,  399,  419,\n",
       "        349,  389,  409,  389,  409,  470,  369, 1008, 1650, 1891, 2356,\n",
       "       1555, 2230, 1435,  500, 2169, 1310, 2783,  849,  609,  640,  379,\n",
       "        340,  320,  339,  300,  340,  300,  340,  310,  329,  340,  390,\n",
       "       1274,  970, 1901,  939,  808,  660,  510,  409,  470, 1674,  699,\n",
       "        669,  460,  349,  359,  329,  310,  310,  339,  349,  329,  310,\n",
       "        459,  550, 1048,  562,  940,  400,  340,  390,  410,  489,  670,\n",
       "        640,  589,  629,  529,  419,  439,  429,  409,  339,  399,  409,\n",
       "        479,  280,  360,  390,  320,  400,  370,  400,  320,  380,  390,\n",
       "        460, 1162,  739,  609,  599,  389,  399,  349,  320,  320,  310,\n",
       "        240,  330,  689,  390,  790,  300,  330,  240,  310,  310,  300,\n",
       "        259,  310,  519, 1577,  589,  689,  570,  409,  269,  310,  309,\n",
       "        249,  300,  320,  339,  260,  369,  390,  419,  459,  450,  320,\n",
       "        390,  569,  459,  599,  520,  908,  720,  619,  629,  389,  419,\n",
       "        389,  279,  310,  310,  250,  309,  699,  409,  968,  449,  410,\n",
       "        450,  330,  240,  310,  340,  420, 1117, 1832, 2246,  610,  619,\n",
       "        310,  300,  290,  270,  320,  320,  250,  289,  330,  890, 1989,\n",
       "        469,  319,  206, 1952,  958, 1317, 1009,  336,  550, 1312,  710,\n",
       "        699,  609,  379,  299,  319,  310,  250,  269,  329,  310,  319,\n",
       "        240,  390, 2156, 2073, 2360,  720, 2241,  869,  549, 1107, 2237,\n",
       "       1298,  419,  359,  430,  410,  429,  249,  319,  310,  300,  250,\n",
       "        319,  319,  310,  359,  609,  420,  421,  559,  580,  460,  680,\n",
       "        620, 1484, 1989, 1295,  670,  649,  490,  379,  300,  339,  269,\n",
       "        269,  319,  329,  609,  479, 1021,  290,  339,  310,  325,  504,\n",
       "        514,  485,  465,  903, 1433,  724,  829,  539,  359,  380,  309,\n",
       "        330,  250,  310,  310,  329,  300,  409,  310,  290,  260,  309,\n",
       "        319,  330,  231,  330,  320,  420, 1526,  789,  790,  679,  339,\n",
       "        320,  240,  329,  310,  329,  210,  339,  399,  689,  350, 1077,\n",
       "        419,  490,  449,  417,  405,  445,  425,  494,  724,  811,  627,\n",
       "        599,  419,  339,  309,  250,  339,  320,  310,  300,  259,  459,\n",
       "        957, 1045,  500,  554,  544,  564,  286,  325,  355,  325, 1653,\n",
       "        565,  614,  584,  399,  329,  330,  260,  339,  310,  339,  310,\n",
       "        300,  449, 1482,  589, 1670,  485,  948,  584,  465,  973,  445,\n",
       "        445,  704,  942,  783,  664,  405,  319,  339,  320,  345,  318,\n",
       "        329,  339,  290,  329,  933,  724,  938, 1129,  923,  515,  445,\n",
       "        574,  614,  545,  494, 1763,  704,  475,  365,  345,  339,  349,\n",
       "        299,  339,  329,  309,  329,  309,  375, 1367,  943,  455,  315,\n",
       "        345,  345,  325,  325,  345,  336,  296,  385,  475,  375,  345,\n",
       "        335,  325,  355,  335,  328,  379,  359,  329,  335,  395,  395,\n",
       "        325,  395,  823, 1033,  524,  435,  494, 1620,  734,  644,  544,\n",
       "        435,  425,  355,  315,  345,  355,  325,  358,  405,  375,  355,\n",
       "        355,  325,  335,  345,  345,  325,  325,  355,  405,  824,  574,\n",
       "        624,  594,  365,  355,  345,  315,  348,  348,  318,  325,  676,\n",
       "        409,  808,  604,  415,  375,  355,  345,  465,  475,  455,  455,\n",
       "        594,  594,  584,  485,  355,  335,  349,  339,  339,  329,  309,\n",
       "        339,  359,  300,  339,  306,  315,  345,  306,  345,  345,  335,\n",
       "        465,  714, 1256,  664,  744,  554,  415,  365,  349,  315,  335,\n",
       "        349,  339,  299,  359,  929, 1608, 1569,  445,  485, 2306, 1898,\n",
       "       1484, 2006, 1306, 2025, 1571, 1942, 1084,  664,  360,  330,  359,\n",
       "        359,  379,  359,  359,  359,  339,  389,  957,  519, 1064,  630,\n",
       "        579,  700,  670,  660,  781,  650, 1799,  639,  550,  490,  459,\n",
       "        329,  300,  310,  330,  319,  229,  319,  329,  350,  659,  640,\n",
       "        560,  679,  619,  600,  790,  550,  560, 1119, 1178,  580,  569,\n",
       "       1627, 1045,  509,  499,  339,  319,  359,  300,  329,  309,  330,\n",
       "        350,  569,  660,  669,  807, 1065, 1571,  550,  660,  530, 1730,\n",
       "        680,  699,  549,  380,  280,  349,  310,  330,  319,  310,  339,\n",
       "        339,  339,  380,  340,  310,  329,  315,  306,  256,  335,  325,\n",
       "        425,  942,  594,  783,  676,  359,  249,  349,  309,  329,  309,\n",
       "        329,  330,  369,  409,  320,  369,  405,  395,  375,  385,  524,\n",
       "        494,  485,  634,  774, 1068,  889, 1275,  439,  310,  349,  289,\n",
       "        319,  300,  319,  329,  339,  340,  310,  310,  228,  309,  330,\n",
       "        325,  306,  415,  514,  514, 1335,  634,  694,  614,  379,  310,\n",
       "        319,  319,  310,  240,  329,  339,  349,  419,  510,  720,  469,\n",
       "        459,  437,  434,  365,  354,  266,  356,  455,  455,  395,  425,\n",
       "        359,  329,  259,  309,  309,  319,  309,  349,  289,  390,  348,\n",
       "       1281, 2038, 2117, 2900, 1190, 2240, 2002, 1904,  614,  605,  714,\n",
       "        654,  564,  811,  425,  883,  355,  345,  315,  335,  335,  289,\n",
       "        368,  385, 1199,  644, 1490, 1902,  674,  634,  624,  584,  654,\n",
       "       1518,  704,  564,  698,  520,  449,  360,  339,  309,  349,  309,\n",
       "        339,  369,  359,  330,  319,  319,  309,  330,  379,  355,  365,\n",
       "        445, 1143, 2167,  751,  659,  600,  390,  390,  340,  290,  349,\n",
       "        319,  319,  359,  619,  449,  939,  310,  259,  429,  689,  710,\n",
       "        750,  915,  830,  860, 1331,  670,  750,  540,  439,  379,  339,\n",
       "        310,  329,  319,  300,  339,  300,  369,  389,  529,  489,  479,\n",
       "        299,  349,  465,  485,  494, 1367,  744,  960,  704, 1102,  319,\n",
       "        330,  309,  329,  319,  310,  330,  309,  339,  389,  879,  679,\n",
       "       1896, 1340, 1660, 1123,  455,  395,  445, 2905, 2517, 1364, 1170,\n",
       "        554,  435,  415,  395,  368,  329,  319,  349,  349,  339,  379,\n",
       "        980,  514, 1719, 1424, 1945, 1223, 1429,  485,  504,  824, 1418])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a87df25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Date' : data['Date'].iloc[2310:], 'Actual' : data['Consumption'].iloc[2310:], 'Predict' : y_predict}).reset_index(drop=True)\n",
    "df.to_csv('C:/Users/user/Desktop/PLoSONE/predict/household_PLoS_XGB.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f8bee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
